{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cac853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append(f'{os.getcwd()}/../src')\n",
    "                \n",
    "from genetist import Genetist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eb06386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7381d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = {\n",
    "    'max_depth': list(range(1, 15)),\n",
    "    'n_estimators': list(range(20, 200)),\n",
    "    'learning_rate': [0.0005, 0.001, 0.01, 0.05, 0.1],\n",
    "    'objective': ['regression', 'regression_l1']\n",
    "}\n",
    "\n",
    "params_space = {\n",
    "    'max_depth': {'low': 1, 'high': 15},\n",
    "    'learning_rate': {'low': 0.0005, 'high': 0.1},\n",
    "    'n_estimators': {'low': 20, 'high': 200},\n",
    "    'objective': {'choices': ['regression', 'regression_l1']},\n",
    "}\n",
    "\n",
    "def objective(individual):\n",
    "    df = pd.read_csv('../datasets/california_housing.csv')\n",
    "    df = pd.get_dummies(df, drop_first=True, dummy_na=True)    \n",
    "    df.dropna(how='any', axis=0, inplace=True)\n",
    "    \n",
    "    X = df.drop('median_house_value', axis=1)\n",
    "    y = df['median_house_value']\n",
    "    \n",
    "    max_depth = individual['max_depth']\n",
    "    learning_rate = individual['learning_rate']\n",
    "    n_estimators = individual['n_estimators']\n",
    "    objective = individual['objective']\n",
    "    \n",
    "    maes = list()\n",
    "    kf = KFold(n_splits=3)\n",
    "    for train_indexes, test_indexes in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_indexes, :], X.iloc[test_indexes, :]\n",
    "        y_train, y_test = y.iloc[train_indexes], y.iloc[test_indexes]\n",
    "        \n",
    "        model = LGBMRegressor(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators, objective=objective, n_jobs=2)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        maes.append(mae)\n",
    "    \n",
    "    return np.mean(maes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cadc3d4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 1 | BEST SCORE IS 45983.06067469037:   3%|▎         | 1/30 [00:11<05:22, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 1 IS: {'max_depth': 9, 'learning_rate': 0.06121366351882034, 'n_estimators': 163, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 2 | BEST SCORE IS 45862.33433796277:   7%|▋         | 2/30 [00:24<05:46, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 2 IS: {'max_depth': 13, 'learning_rate': 0.06620300076589586, 'n_estimators': 186, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 3 | BEST SCORE IS 45430.72512792883:  10%|█         | 3/30 [00:40<06:17, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 3 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 163, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 4 | BEST SCORE IS 45430.72512792883:  13%|█▎        | 4/30 [00:56<06:29, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 4 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 163, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 5 | BEST SCORE IS 45430.72512792883:  17%|█▋        | 5/30 [01:14<06:38, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 5 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 163, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 6 | BEST SCORE IS 45410.97436604267:  20%|██        | 6/30 [01:31<06:29, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 6 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 186, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 7 | BEST SCORE IS 45410.97436604267:  23%|██▎       | 7/30 [01:48<06:20, 16.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 7 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 186, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 8 | BEST SCORE IS 45410.97436604267:  27%|██▋       | 8/30 [02:05<06:07, 16.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 8 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 186, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 9 | BEST SCORE IS 45410.97436604267:  30%|███       | 9/30 [02:23<06:00, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 9 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 186, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 10 | BEST SCORE IS 45410.97436604267:  33%|███▎      | 10/30 [02:43<05:57, 17.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 10 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 186, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 11 | BEST SCORE IS 45410.97436604267:  37%|███▋      | 11/30 [03:02<05:47, 18.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 11 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 186, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 12 | BEST SCORE IS 45389.063977776656:  40%|████      | 12/30 [03:20<05:28, 18.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 12 IS: {'max_depth': 15, 'learning_rate': 0.07659821965048146, 'n_estimators': 186, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 13 | BEST SCORE IS 45169.47137451967:  43%|████▎     | 13/30 [03:38<05:10, 18.29s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 13 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 197, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 14 | BEST SCORE IS 45169.47137451967:  47%|████▋     | 14/30 [03:58<04:57, 18.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 14 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 197, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 15 | BEST SCORE IS 45126.554789602065:  50%|█████     | 15/30 [04:17<04:42, 18.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 15 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 16 | BEST SCORE IS 45126.554789602065:  53%|█████▎    | 16/30 [04:37<04:28, 19.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 16 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 17 | BEST SCORE IS 45126.554789602065:  57%|█████▋    | 17/30 [04:56<04:08, 19.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 17 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 18 | BEST SCORE IS 45126.554789602065:  60%|██████    | 18/30 [05:16<03:51, 19.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 18 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 19 | BEST SCORE IS 45126.554789602065:  63%|██████▎   | 19/30 [05:35<03:31, 19.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 19 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 20 | BEST SCORE IS 45126.554789602065:  67%|██████▋   | 20/30 [05:54<03:11, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 20 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 21 | BEST SCORE IS 45126.554789602065:  70%|███████   | 21/30 [06:13<02:52, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 21 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 22 | BEST SCORE IS 45126.554789602065:  73%|███████▎  | 22/30 [06:33<02:34, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 22 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 23 | BEST SCORE IS 45126.554789602065:  77%|███████▋  | 23/30 [06:51<02:13, 19.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 23 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 24 | BEST SCORE IS 45126.554789602065:  80%|████████  | 24/30 [07:11<01:55, 19.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 24 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 25 | BEST SCORE IS 45126.554789602065:  83%|████████▎ | 25/30 [07:30<01:36, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 25 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 26 | BEST SCORE IS 45126.554789602065:  87%|████████▋ | 26/30 [07:49<01:17, 19.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 26 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 27 | BEST SCORE IS 45126.554789602065:  90%|█████████ | 27/30 [08:10<00:59, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 27 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 28 | BEST SCORE IS 45126.554789602065:  93%|█████████▎| 28/30 [08:30<00:39, 19.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 28 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 29 | BEST SCORE IS 45126.554789602065:  97%|█████████▋| 29/30 [08:51<00:19, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 29 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RUNNING GENERATION 30 | BEST SCORE IS 45126.554789602065: 100%|██████████| 30/30 [09:11<00:00, 18.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE BEST SOLUTION IN GENERATION 30 IS: {'max_depth': 12, 'learning_rate': 0.07659821965048146, 'n_estimators': 196, 'objective': 'regression_l1'}\n",
      "\n",
      "EXECUTION TIME=0 hours 09 minutes 19.602670 seconds\n",
      "BEST SCORE=45126.554789602065\n",
      "BEST INDIVIDUAL=[12, 0.07659821965048146, 196, 'regression_l1']\n",
      "BEST PER GENERATION:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENERATION</th>\n",
       "      <th>BEST_SCORE</th>\n",
       "      <th>BEST_INDIVIDUAL</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>objective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>45126.554790</td>\n",
       "      <td>[12, 0.07659821965048146, 196, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>196</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>45169.471375</td>\n",
       "      <td>[12, 0.07659821965048146, 197, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>197</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>45169.471375</td>\n",
       "      <td>[12, 0.07659821965048146, 197, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>197</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>45389.063978</td>\n",
       "      <td>[15, 0.07659821965048146, 186, regression_l1]</td>\n",
       "      <td>15</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>186</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>45410.974366</td>\n",
       "      <td>[12, 0.07659821965048146, 186, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>186</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>45410.974366</td>\n",
       "      <td>[12, 0.07659821965048146, 186, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>186</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>45410.974366</td>\n",
       "      <td>[12, 0.07659821965048146, 186, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>186</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>45410.974366</td>\n",
       "      <td>[12, 0.07659821965048146, 186, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>186</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>45410.974366</td>\n",
       "      <td>[12, 0.07659821965048146, 186, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>186</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>45410.974366</td>\n",
       "      <td>[12, 0.07659821965048146, 186, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>186</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>45430.725128</td>\n",
       "      <td>[12, 0.07659821965048146, 163, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>163</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>45430.725128</td>\n",
       "      <td>[12, 0.07659821965048146, 163, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>163</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>45430.725128</td>\n",
       "      <td>[12, 0.07659821965048146, 163, regression_l1]</td>\n",
       "      <td>12</td>\n",
       "      <td>0.076598</td>\n",
       "      <td>163</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45862.334338</td>\n",
       "      <td>[13, 0.06620300076589586, 186, regression_l1]</td>\n",
       "      <td>13</td>\n",
       "      <td>0.066203</td>\n",
       "      <td>186</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>45983.060675</td>\n",
       "      <td>[9, 0.06121366351882034, 163, regression_l1]</td>\n",
       "      <td>9</td>\n",
       "      <td>0.061214</td>\n",
       "      <td>163</td>\n",
       "      <td>regression_l1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GENERATION    BEST_SCORE                                BEST_INDIVIDUAL  \\\n",
       "14          15  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "27          28  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "26          27  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "25          26  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "24          25  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "23          24  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "22          23  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "21          22  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "20          21  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "19          20  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "18          19  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "17          18  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "16          17  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "15          16  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "29          30  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "28          29  45126.554790  [12, 0.07659821965048146, 196, regression_l1]   \n",
       "13          14  45169.471375  [12, 0.07659821965048146, 197, regression_l1]   \n",
       "12          13  45169.471375  [12, 0.07659821965048146, 197, regression_l1]   \n",
       "11          12  45389.063978  [15, 0.07659821965048146, 186, regression_l1]   \n",
       "10          11  45410.974366  [12, 0.07659821965048146, 186, regression_l1]   \n",
       "9           10  45410.974366  [12, 0.07659821965048146, 186, regression_l1]   \n",
       "8            9  45410.974366  [12, 0.07659821965048146, 186, regression_l1]   \n",
       "7            8  45410.974366  [12, 0.07659821965048146, 186, regression_l1]   \n",
       "6            7  45410.974366  [12, 0.07659821965048146, 186, regression_l1]   \n",
       "5            6  45410.974366  [12, 0.07659821965048146, 186, regression_l1]   \n",
       "4            5  45430.725128  [12, 0.07659821965048146, 163, regression_l1]   \n",
       "3            4  45430.725128  [12, 0.07659821965048146, 163, regression_l1]   \n",
       "2            3  45430.725128  [12, 0.07659821965048146, 163, regression_l1]   \n",
       "1            2  45862.334338  [13, 0.06620300076589586, 186, regression_l1]   \n",
       "0            1  45983.060675   [9, 0.06121366351882034, 163, regression_l1]   \n",
       "\n",
       "    max_depth  learning_rate  n_estimators      objective  \n",
       "14         12       0.076598           196  regression_l1  \n",
       "27         12       0.076598           196  regression_l1  \n",
       "26         12       0.076598           196  regression_l1  \n",
       "25         12       0.076598           196  regression_l1  \n",
       "24         12       0.076598           196  regression_l1  \n",
       "23         12       0.076598           196  regression_l1  \n",
       "22         12       0.076598           196  regression_l1  \n",
       "21         12       0.076598           196  regression_l1  \n",
       "20         12       0.076598           196  regression_l1  \n",
       "19         12       0.076598           196  regression_l1  \n",
       "18         12       0.076598           196  regression_l1  \n",
       "17         12       0.076598           196  regression_l1  \n",
       "16         12       0.076598           196  regression_l1  \n",
       "15         12       0.076598           196  regression_l1  \n",
       "29         12       0.076598           196  regression_l1  \n",
       "28         12       0.076598           196  regression_l1  \n",
       "13         12       0.076598           197  regression_l1  \n",
       "12         12       0.076598           197  regression_l1  \n",
       "11         15       0.076598           186  regression_l1  \n",
       "10         12       0.076598           186  regression_l1  \n",
       "9          12       0.076598           186  regression_l1  \n",
       "8          12       0.076598           186  regression_l1  \n",
       "7          12       0.076598           186  regression_l1  \n",
       "6          12       0.076598           186  regression_l1  \n",
       "5          12       0.076598           186  regression_l1  \n",
       "4          12       0.076598           163  regression_l1  \n",
       "3          12       0.076598           163  regression_l1  \n",
       "2          12       0.076598           163  regression_l1  \n",
       "1          13       0.066203           186  regression_l1  \n",
       "0           9       0.061214           163  regression_l1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genetist = Genetist(\n",
    "    params=params_space,\n",
    "    num_population=30,\n",
    "    generations=30,\n",
    "    elite_rate=0.1,\n",
    "    prob_mutation=0.1,\n",
    ")\n",
    "\n",
    "results = genetist.optimize(objective=objective, direction='minimize')\n",
    "\n",
    "print()\n",
    "print(f'EXECUTION TIME={results.execution_time}')\n",
    "print(f'BEST SCORE={results.best_score}')\n",
    "print(f'BEST INDIVIDUAL={results.best_individual}')\n",
    "print('BEST PER GENERATION:')\n",
    "display(results.best_per_generation_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a38720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_plot = results.best_per_generation_dataframe.sort_values(by=['GENERATION'])\n",
    "df_plot.BEST_SCORE.plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825a0b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
